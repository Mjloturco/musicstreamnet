{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parallel_Input.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyk94GZNakCDRYFPHDkZFx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mjloturco/musicstreamnet/blob/main/Parallel_Input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Parallel Input"
      ],
      "metadata": {
        "id": "HAv226rsEJnV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeULab2B-n3u",
        "outputId": "b618b364-4f9e-4b48-e3ce-90cc6a5af99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.layers.merge import concatenate\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "_W3BCoUODjyD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "metadata": {
        "id": "h1dqF3Ome7uZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "1T9_nh0xEgll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Series"
      ],
      "metadata": {
        "id": "wb6_HCkHcaUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/My Drive/cs137/project/spotify_daily_song_major.csv')\n",
        "df = pd.read_csv('/content/drive/My Drive/cs137/project/spotify_daily_charts.csv')"
      ],
      "metadata": {
        "id": "alLOQ6tT_hhM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['track_name', 'artist', 'position'])\n",
        "df.head()\n",
        "\n",
        "timesteps = df['date'].unique()"
      ],
      "metadata": {
        "id": "BZd2wxpdAMrr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot = pd.pivot_table(df, values='streams', index=['date'], columns=['track_id'])\n",
        "df_pivot.head()"
      ],
      "metadata": {
        "id": "fhE-2_dYBLS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out songs without a lot of stream counts \n",
        "df_pivot = df_pivot.dropna(axis=1, thresh=800)\n",
        "\n",
        "# fill NaN values with 0???\n",
        "# df_pivot = df_pivot.fillna(0)\n",
        "df_pivot = df_pivot.interpolate(method='linear', axis=1, limit=2)\n",
        "df_pivot = df_pivot.fillna(0)"
      ],
      "metadata": {
        "id": "ftR4qn6zB0KN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.options.display.max_rows = None\n",
        "# df_pivot.iloc[:, 1]"
      ],
      "metadata": {
        "id": "sbuJd7t3CPbK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get last 20% of songs\n",
        "split = df['date'].unique()[-int(1598*0.2)]\n",
        "\n",
        "df_train = df_pivot.loc[:split]\n",
        "df_test = df_pivot.loc[split:]"
      ],
      "metadata": {
        "id": "HuxazlHtDfLx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min-max scaling \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "\n",
        "l = [i for i in df_pivot if i != 'date']\n",
        "\n",
        "scaler = MinMaxScaler() \n",
        "scaled_train = scaler.fit_transform(df_train[l])\n",
        "scaled_test = scaler.fit_transform(df_test[l])\n"
      ],
      "metadata": {
        "id": "JJlZ9vcQGOaO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequence(sequence, look_back, forecast_horizon):\n",
        "  \"\"\"\n",
        "  splitting sequence\n",
        "  \"\"\"\n",
        "  X, y = list(), list() \n",
        "  \n",
        "  for i in range(len(sequence)):\n",
        "\n",
        "    lag_end = i + look_back\n",
        "    forecast_end = lag_end + forecast_horizon \n",
        "\n",
        "    if forecast_end > len(sequence):\n",
        "      break \n",
        "\n",
        "    seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  \n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# splitting parameters \n",
        "LOOK_BACK = 12\n",
        "FORECAST_RANGE = 1\n",
        "n_features = len(l)\n",
        "\n",
        "X_train, y_train = split_sequence(scaled_train, LOOK_BACK, FORECAST_RANGE)\n",
        "X_test, y_test = split_sequence(scaled_test, LOOK_BACK, FORECAST_RANGE)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHcTIE4dG6tj",
        "outputId": "31cb03c3-b44c-4d30-df1a-929df47a2ec1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1268, 12, 63) (1268, 1, 63) (307, 12, 63) (307, 1, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata"
      ],
      "metadata": {
        "id": "I6lAZu9-cdIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta = pd.read_csv('/content/drive/My Drive/cs137/project/spotify_tracks_augmented.csv').set_index('track_id')\n",
        "\n",
        "# select only track IDs that we've filtered above \n",
        "meta = meta.loc[df_pivot.columns]\n",
        "\n",
        "\n",
        "# drop columns \n",
        "dropcols = ['Unnamed: 0', 'artist_id', 'type', 'id', 'uri', \n",
        "            'track_href', 'analysis_url']\n",
        "\n",
        "meta = meta.drop(columns=dropcols)\n",
        "\n",
        "metasize = meta.shape[1]\n",
        "\n",
        "# show metadata\n",
        "print(meta.shape)\n",
        "meta"
      ],
      "metadata": {
        "id": "XVFbFuWCceU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "BDbSjOk7Eodc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configure callbacks \n",
        "\n",
        "checkpoint_filepath = 'path_to_checkpoint_filepath'\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        " filepath=checkpoint_filepath,\n",
        " save_weights_only=False,\n",
        " monitor='val_loss',\n",
        " mode='min',\n",
        " save_best_only=True)\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        " monitor='val_loss',\n",
        " min_delta=0.005,\n",
        " patience=10,\n",
        " mode='min'\n",
        ")\n",
        "\n",
        "rlrop_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode='min', patience=3, min_lr=0.001)"
      ],
      "metadata": {
        "id": "K-Hne4g5M5VG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential"
      ],
      "metadata": {
        "id": "uN3WfWVybXwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION = 0.1 \n",
        "\n",
        "# SEQUENTIAL MODEL \n",
        "seq_model = Sequential()\n",
        "seq_model.add(LSTM(12, activation='relu', input_shape=(LOOK_BACK, n_features)))\n",
        "seq_model.add(RepeatVector(FORECAST_RANGE))\n",
        "seq_model.add(LSTM(12, activation='relu', return_sequences=True)) \n",
        "seq_model.add(TimeDistributed(Dense(n_features)))\n",
        "\n",
        "seq_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "seq_history = seq_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
        "                    validation_split=VALIDATION, callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccMTMeoaJtmH",
        "outputId": "0dd174a1-a76f-43ec-e09a-599115cd3bbd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 2s 15ms/step - loss: 0.1399 - val_loss: 0.0711\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1005 - val_loss: 0.0417\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0499 - val_loss: 0.0219\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.0192\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0192\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0185\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0178\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0166\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0156\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0145\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0140\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0132\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0129\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0124\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0124\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0120\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0122\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functional"
      ],
      "metadata": {
        "id": "FICfmGT0baS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "swapped = np.swapaxes(meta, 0, 1)\n",
        "\n",
        "swapped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvchmQjTjTFk",
        "outputId": "bc50609c-63b7-4bcc-b6e1-6b0ca1a0b46b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:, 0, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIT64cEZt0fu",
        "outputId": "07a50c30-f83f-4879-f6e7-eef5f0ce7d24"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.15871822, 0.12787845, 0.12587796, ..., 0.09610414, 0.10121977,\n",
              "       0.13171639])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION = 0.1 \n",
        "\n",
        "#                examples, timesteps, song\n",
        "# input train shape (1265, 12, 63)\n",
        "# train out         (1265, 4, 63) \n",
        "# test in           (304, 12, 63)\n",
        "# test out          (304, 4, 63)\n",
        "\n",
        "song_count = 63\n",
        "\n",
        "# MODEL \n",
        "time_series_input = Input(shape=(12, song_count))\n",
        "lstm_out_size = 12\n",
        "lstm_out = LSTM(lstm_out_size)(time_series_input)\n",
        "repeat_out = RepeatVector(FORECAST_RANGE)(lstm_out)\n",
        "lstm2_out = LSTM(12, activation='relu', return_sequences=True)(repeat_out) \n",
        "dense_layer = Dense(song_count)\n",
        "td_out = TimeDistributed(dense_layer)(lstm2_out)\n",
        "\n",
        "# METADATA + concatenation\n",
        "meta_input = Input(shape=(metasize, song_count))\n",
        "full_features = concatenate([td_out, meta_input], axis=1)\n",
        "swapped_features = tf.keras.layers.Permute((2, 1))(full_features)\n",
        "d1 = Dense(16, activation='relu')(swapped_features) \n",
        "d2 = Dense(8, activation='tanh')(d1)\n",
        "d3 = Dense(4, activation='tanh')(d2)\n",
        "d4 = Dense(1, activation='linear')(d3)\n",
        "# final = tf.keras.layers.Permute((2, 1))(d3)\n",
        "\n",
        "# #outputshape\n",
        "# output = Dense(1, activation='linear')(d1)\n",
        "\n",
        "# # create model \n",
        "fun_model = Model(inputs=[time_series_input, meta_input], outputs=d4)\n",
        "\n",
        "# # compile \n",
        "# model.compile(loss='mse', optimizer='adam')\n",
        "fun_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# stack metadata to match shape \n",
        "tiled = np.tile(np.swapaxes(np.expand_dims(meta, axis=0), 1, 2), [1268, 1, 1])\n",
        "\n",
        "print(fun_model.summary())\n",
        "\n",
        "X = [X_train[:, :, :song_count], tiled[:, :, :song_count]]\n",
        "# Y = y_train[:, :, :song_count]\n",
        "Y = np.swapaxes(y_train[:, :, :song_count], 1, 2)\n",
        "fun_history = fun_model.fit(x=X, y=Y, \n",
        "                            epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                            validation_split=VALIDATION, \n",
        "                            callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be823ddd-26bc-4431-b090-7c647149a9c6",
        "id": "30XUDE_lc4-I"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_47 (InputLayer)          [(None, 12, 63)]     0           []                               \n",
            "                                                                                                  \n",
            " lstm_50 (LSTM)                 (None, 12)           3648        ['input_47[0][0]']               \n",
            "                                                                                                  \n",
            " repeat_vector_25 (RepeatVector  (None, 1, 12)       0           ['lstm_50[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lstm_51 (LSTM)                 (None, 1, 12)        1200        ['repeat_vector_25[0][0]']       \n",
            "                                                                                                  \n",
            " time_distributed_25 (TimeDistr  (None, 1, 63)       819         ['lstm_51[0][0]']                \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " input_48 (InputLayer)          [(None, 13, 63)]     0           []                               \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 14, 63)       0           ['time_distributed_25[0][0]',    \n",
            "                                                                  'input_48[0][0]']               \n",
            "                                                                                                  \n",
            " permute_18 (Permute)           (None, 63, 14)       0           ['concatenate_23[0][0]']         \n",
            "                                                                                                  \n",
            " dense_79 (Dense)               (None, 63, 16)       240         ['permute_18[0][0]']             \n",
            "                                                                                                  \n",
            " dense_80 (Dense)               (None, 63, 8)        136         ['dense_79[0][0]']               \n",
            "                                                                                                  \n",
            " dense_81 (Dense)               (None, 63, 4)        36          ['dense_80[0][0]']               \n",
            "                                                                                                  \n",
            " dense_82 (Dense)               (None, 63, 1)        5           ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,084\n",
            "Trainable params: 6,084\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 3s 24ms/step - loss: 0.0522 - val_loss: 0.0343\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0343\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0518 - val_loss: 0.0341\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0350\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0518 - val_loss: 0.0351\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0518 - val_loss: 0.0360\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0517 - val_loss: 0.0365\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0517 - val_loss: 0.0367\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0518 - val_loss: 0.0367\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.0517 - val_loss: 0.0366\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 1s 17ms/step - loss: 0.0517 - val_loss: 0.0356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuvP6-IHfoES",
        "outputId": "c91d0988-41c0-401c-f0b4-4c2d9326ca53"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307, 63, 1)\n",
            "(1268, 12, 63) (1268, 1, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "3LPsKny6Esi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick which model we're evaluating \n",
        "\n",
        "model = fun_model\n",
        "history = fun_history \n",
        "\n",
        "print(X_test.shape, meta.shape)\n",
        "testmeta = np.tile(np.swapaxes(np.expand_dims(meta, axis=0), 1, 2), [307, 1, 1])\n",
        "print(testmeta.shape)\n",
        "\n",
        "test = [X_test, testmeta]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzAph80BboC0",
        "outputId": "4e127cf5-e12d-4610-83c3-348385825003"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307, 12, 63) (63, 13)\n",
            "(307, 13, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for model eval\n",
        "\n",
        "\n",
        "def inverse_transform(y_test, yhat):\n",
        "  \"\"\"\n",
        "  revert data back to original scale for evaluation\n",
        "  \"\"\"\n",
        "  y_test_reshaped = y_test.reshape(-1, y_test.shape[-1])\n",
        "  yhat_reshaped = yhat.reshape(-1, yhat.shape[-1])\n",
        "\n",
        "  yhat_inverse = scaler.inverse_transform(yhat_reshaped)\n",
        "  y_test_inverse = scaler.inverse_transform(y_test_reshaped)\n",
        "\n",
        "  return yhat_inverse, y_test_inverse \n",
        "\n",
        "  \n",
        "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
        "  \"\"\"\n",
        "  Evaluation metrics \n",
        "  \"\"\"\n",
        "  mse_ = tf.keras.losses.MeanSquaredError()\n",
        "  rmse_ = tf.keras.metrics.RootMeanSquaredError()\n",
        "  mae_ = tf.keras.losses.MeanAbsoluteError()\n",
        "  mape_ = tf.keras.losses.MeanAbsolutePercentageError() \n",
        "\n",
        "  mse = mse_(y_test_inverse,yhat_inverse)\n",
        "  tf.print('mse:', mse)\n",
        "\n",
        "  rmse = rmse_(y_test_inverse, yhat_inverse)\n",
        "  tf.print('rmse:', rmse)\n",
        "\n",
        "  mae = mae_(y_test_inverse,yhat_inverse)\n",
        "  tf.print('mae:', mae)\n",
        "\n",
        "  mape = mape_(y_test_inverse,yhat_inverse)\n",
        "  tf.print('mape:', mape)\n",
        "\n"
      ],
      "metadata": {
        "id": "cTYCURTaH_x9"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(test, verbose=0)\n",
        "\n",
        "# yhat_inverse, y_test_inverse = inverse_transform(y_test, yhat)\n",
        "\n",
        "print(y_test_inverse.shape, yhat_inverse.shape, yhat.shape)\n",
        "# evaluate_forecast(y_test_inverse, yhat_inverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkVDHaboKyee",
        "outputId": "ee6b15bf-c9e9-49c2-8c7c-37fc3de709ff"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307, 63) (307, 63) (307, 63, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat[:, 1, 0]"
      ],
      "metadata": {
        "id": "_Y5iofrCtruY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat_inverse.shape, y_test_inverse.shape, y_test.shape, yhat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teOFadFex7c0",
        "outputId": "0fccab58-e8f6-4782-9474-2f1d22a1ac89"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307, 63) (307, 63) (307, 1, 63) (307, 63, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# timesteps, batches?, songs \n",
        "print(yhat.shape)\n",
        "print(yhat_inverse.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6IhyytduWhD",
        "outputId": "799d5378-02ef-4fae-a668-9937d51f8818"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307, 1, 63)\n",
            "(307, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# visualize loss\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jUPPMnowN_1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(timesteps[-304:], yhat, label='pred')\n",
        "# plt.plot(timesteps[-304:], y_test, label='test') \n",
        "# plt.show()\n",
        "plt.figure(figsize=(32, 32))\n",
        "\n",
        "ntimesteps = yhat.shape[0]\n",
        "\n",
        "fig, axs = plt.subplots(8, 8, figsize=(32, 32))\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.plot(timesteps[-ntimesteps:], yhat[:, 0, i-1], label='pred')\n",
        "  ax.plot(timesteps[-ntimesteps:], y_test[:, 0, i-1], label='test')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(timesteps[-304:], yhat[:, 0, 16], label='pred')\n",
        "# plt.plot(timesteps[-304:], y_test[:, 0, 16], label='test')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gaUdWgfKyApJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}